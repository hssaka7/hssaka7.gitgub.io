[
  {
    "objectID": "core/blog.html",
    "href": "core/blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nLinear Regression using DNN\n\n\n\n\n\n Linear regression of California housing dataset using deep neural networks\n\n\n\n\n\nMar 4, 2024\n\n\nAakash Basnet\n\n\n\n\n\n\n\n\n\n\n\n\nImage classification\n\n\n\n\n\n image classification of Fashion MINST dataset\n\n\n\n\n\nFeb 19, 2024\n\n\nAakash Basnet\n\n\n\n\n\n\n\n\n\n\n\n\nWebscraping Indeed Job Portal\n\n\n\n\n\nwebscraping with python \n\n\n\n\n\nFeb 3, 2024\n\n\nAakash Basnet\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html",
    "href": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html",
    "title": "Tyler Ryan",
    "section": "",
    "text": "Explore our comprehensive suite of services, offering web scraping, data mining, and data extraction solutions tailored for lead generation, business process automation, research, and marketing initiatives.\n\n\nOur web scrapers, written in Python (utilizing BeautifulSoup, Requests, Selenium), ensure precise data extraction, filtration, and packaging in versatile formats, including CSV, JSON, and XML.\n\n\n\n\nExtract data tables, text, images, and links, among other elements.\nFilter and compile data into various formats: JSON, XML, CSV, and SQL.\nSet up alerts for new content discovery.\nCapture screenshots or download full HTML of websites.\nConduct “real” interactions with websites, including clicking buttons, accessing drop-downs, and entering text into forms.\n\n\n\n\nUtilizing Python BeautifulSoup, Requests, Selenium, and Headless Chrome.\n\n\n\n\nSystem to rename thousands of images files stored in Dropbox using Python and Dropbox API.\nWeb app to translate Excel documents with Python Flask and Google Cloud Translation API.\nScraped a list of 100,000 funeral homes across the U.S.\nScraped a list of 3,000 martial arts institutes in the UK, identifying site tools, mobile responsiveness, and page load speed.\nAutomated scraping of property listings and publishing to a WordPress site.\nScraped product listings from a home appliances vendor using Selenium.\nDeveloped a system to scrape job listings from Indeed and import into a WordPress-based website.\n\n\n\n\nDo you have a web scraping, data extraction, or business process automation requirement? Let’s discuss how we can elevate your operations."
  },
  {
    "objectID": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html#custom-web-scrapers",
    "href": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html#custom-web-scrapers",
    "title": "Tyler Ryan",
    "section": "",
    "text": "Our web scrapers, written in Python (utilizing BeautifulSoup, Requests, Selenium), ensure precise data extraction, filtration, and packaging in versatile formats, including CSV, JSON, and XML."
  },
  {
    "objectID": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html#web-scraping-features",
    "href": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html#web-scraping-features",
    "title": "Tyler Ryan",
    "section": "",
    "text": "Extract data tables, text, images, and links, among other elements.\nFilter and compile data into various formats: JSON, XML, CSV, and SQL.\nSet up alerts for new content discovery.\nCapture screenshots or download full HTML of websites.\nConduct “real” interactions with websites, including clicking buttons, accessing drop-downs, and entering text into forms."
  },
  {
    "objectID": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html#scraping-tools",
    "href": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html#scraping-tools",
    "title": "Tyler Ryan",
    "section": "",
    "text": "Utilizing Python BeautifulSoup, Requests, Selenium, and Headless Chrome."
  },
  {
    "objectID": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html#recent-projects",
    "href": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html#recent-projects",
    "title": "Tyler Ryan",
    "section": "",
    "text": "System to rename thousands of images files stored in Dropbox using Python and Dropbox API.\nWeb app to translate Excel documents with Python Flask and Google Cloud Translation API.\nScraped a list of 100,000 funeral homes across the U.S.\nScraped a list of 3,000 martial arts institutes in the UK, identifying site tools, mobile responsiveness, and page load speed.\nAutomated scraping of property listings and publishing to a WordPress site.\nScraped product listings from a home appliances vendor using Selenium.\nDeveloped a system to scrape job listings from Indeed and import into a WordPress-based website."
  },
  {
    "objectID": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html#get-in-touch",
    "href": "core/testimonials/1_Tyler_Ryan/tyler_ryan.html#get-in-touch",
    "title": "Tyler Ryan",
    "section": "",
    "text": "Do you have a web scraping, data extraction, or business process automation requirement? Let’s discuss how we can elevate your operations."
  },
  {
    "objectID": "core/blogs/Linear-regression-using-DNN/Linear-regression-using-DNN.html",
    "href": "core/blogs/Linear-regression-using-DNN/Linear-regression-using-DNN.html",
    "title": "Linear Regression using DNN",
    "section": "",
    "text": "Code\n\nimport pandas as pd"
  },
  {
    "objectID": "core/blogs/Linear-regression-using-DNN/Linear-regression-using-DNN.html#linear-regression-of-california-housing-dataset-using-deep-neural-networks",
    "href": "core/blogs/Linear-regression-using-DNN/Linear-regression-using-DNN.html#linear-regression-of-california-housing-dataset-using-deep-neural-networks",
    "title": "Linear Regression using DNN",
    "section": "",
    "text": "Code\n\nimport pandas as pd"
  },
  {
    "objectID": "core/blogs/image_classification/image_classification.html",
    "href": "core/blogs/image_classification/image_classification.html",
    "title": "Image classification",
    "section": "",
    "text": "Code\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\n\nfashion_data = tf.keras.datasets.fashion_mnist\n(train_data, train_label) , (test_data, test_label) = fashion_data.load_data()\n\n\n2.15.0"
  },
  {
    "objectID": "core/blogs/image_classification/image_classification.html#import-the-fashion-mnist-dataset",
    "href": "core/blogs/image_classification/image_classification.html#import-the-fashion-mnist-dataset",
    "title": "Image classification",
    "section": "",
    "text": "Code\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\n\nfashion_data = tf.keras.datasets.fashion_mnist\n(train_data, train_label) , (test_data, test_label) = fashion_data.load_data()\n\n\n2.15.0"
  },
  {
    "objectID": "core/blogs/image_classification/image_classification.html#preprocessing-the-data",
    "href": "core/blogs/image_classification/image_classification.html#preprocessing-the-data",
    "title": "Image classification",
    "section": "Preprocessing the data",
    "text": "Preprocessing the data\n\n\nCode\ntrain_data.shape\n\n\n(60000, 28, 28)\n\n\n\n\nCode\ntest_label.shape\n\n\n(10000,)\n\n\n\n\nCode\nplt.figure()\nplt.imshow(train_data[0])\nplt.colorbar()\nplt.grid(False)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nx_valid, x_train = train_data[:5000] / 255.0, train_data[5000:]/255.0\ny_valid, y_train = train_label[:5000], train_label[5000:]\n\n\n\n\nCode\nclass_map = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n\n\n\nCode\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.xlabel(class_map[train_label[i]])\n    plt.imshow(train_data[i])\nplt.show()"
  },
  {
    "objectID": "core/blogs/image_classification/image_classification.html#building-the-model-using-neural-network",
    "href": "core/blogs/image_classification/image_classification.html#building-the-model-using-neural-network",
    "title": "Image classification",
    "section": "Building the model using neural network",
    "text": "Building the model using neural network\nSequential Model is the simplest form of Model that keras library provides. It is composed of a single stack of layer connected sequentially. Also, known as sequential API. The first layer in the model is is Flatten model ,which simply flattens the 2D image array to 1D. Then, the Dense layer with 300 neurons which uses Relu as an activation function is stacked. Then, there is second Dense layer with 100 neurons , with same Relu as activation function. The final layer in the model stack is output layuer, which is also a Dense layer with 10 neurons (one per class) and it uses softmax function for multi-class classification.\n\n\nCode\ninput_layer = tf.keras.layers.Flatten(input_shape=(28,28))\ndense_layer1 = tf.keras.layers.Dense(300, activation='relu')\ndense_layer2 = tf.keras.layers.Dense(100, activation='relu')\noutput_layer = tf.keras.layers.Dense(10, activation = 'softmax')\n\nmodel = tf.keras.Sequential([input_layer,dense_layer1, dense_layer2 ,output_layer])\noptimizer = 'adam'\nloss_function = tf.keras.losses.SparseCategoricalCrossentropy()\nmetrics = ['accuracy']\n\nmodel.summary()\n\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense (Dense)               (None, 300)               235500    \n                                                                 \n dense_1 (Dense)             (None, 100)               30100     \n                                                                 \n dense_2 (Dense)             (None, 10)                1010      \n                                                                 \n=================================================================\nTotal params: 266610 (1.02 MB)\nTrainable params: 266610 (1.02 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________"
  },
  {
    "objectID": "core/blogs/image_classification/image_classification.html#training-the-model",
    "href": "core/blogs/image_classification/image_classification.html#training-the-model",
    "title": "Image classification",
    "section": "Training the model",
    "text": "Training the model\n\n\nCode\nmodel.compile(optimizer=optimizer, loss= loss_function, metrics=metrics )\nhistory = model.fit(x_train,y_train, epochs=10, validation_data = (x_valid, y_valid))\n\n\nEpoch 1/10\n1719/1719 [==============================] - 2s 852us/step - loss: 0.4921 - accuracy: 0.8241 - val_loss: 0.3733 - val_accuracy: 0.8646\nEpoch 2/10\n1719/1719 [==============================] - 1s 788us/step - loss: 0.3670 - accuracy: 0.8647 - val_loss: 0.3491 - val_accuracy: 0.8706\nEpoch 3/10\n1719/1719 [==============================] - 2s 891us/step - loss: 0.3282 - accuracy: 0.8789 - val_loss: 0.3108 - val_accuracy: 0.8846\nEpoch 4/10\n1719/1719 [==============================] - 1s 775us/step - loss: 0.3058 - accuracy: 0.8853 - val_loss: 0.3005 - val_accuracy: 0.8934\nEpoch 5/10\n1719/1719 [==============================] - 1s 822us/step - loss: 0.2847 - accuracy: 0.8929 - val_loss: 0.3024 - val_accuracy: 0.8876\nEpoch 6/10\n1719/1719 [==============================] - 1s 769us/step - loss: 0.2725 - accuracy: 0.8971 - val_loss: 0.3025 - val_accuracy: 0.8932\nEpoch 7/10\n1719/1719 [==============================] - 1s 799us/step - loss: 0.2566 - accuracy: 0.9029 - val_loss: 0.2946 - val_accuracy: 0.8966\nEpoch 8/10\n1719/1719 [==============================] - 1s 776us/step - loss: 0.2473 - accuracy: 0.9064 - val_loss: 0.3052 - val_accuracy: 0.8944\nEpoch 9/10\n1719/1719 [==============================] - 1s 784us/step - loss: 0.2394 - accuracy: 0.9109 - val_loss: 0.3212 - val_accuracy: 0.8896\nEpoch 10/10\n1719/1719 [==============================] - 1s 818us/step - loss: 0.2280 - accuracy: 0.9131 - val_loss: 0.3100 - val_accuracy: 0.8936\n\n\n\n\nCode\n\npd.DataFrame(history.history).plot()\nplt.grid(True)\nplt.gca().set_ylim(0,1)\nplt.show()"
  },
  {
    "objectID": "core/blogs/image_classification/image_classification.html#testing-the-model",
    "href": "core/blogs/image_classification/image_classification.html#testing-the-model",
    "title": "Image classification",
    "section": "Testing the model",
    "text": "Testing the model\n\n\nCode\ntest_loss, test_acc = model.evaluate(test_data, test_label)\n\n\n\n313/313 [==============================] - 0s 433us/step - loss: 55.4865 - accuracy: 0.8696"
  },
  {
    "objectID": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html",
    "href": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html",
    "title": "Artificial Intelligence",
    "section": "",
    "text": "Uncover the future of business innovation through our cutting-edge Artificial Intelligence services, meticulously designed to transform operations and inspire insightful advancements.\n\n\nExperience the pinnacle of AI solutions tailored precisely to your unique business demands, leveraging a suite of sophisticated tools and technologies.\n\n\n\nEmbark on a journey of comprehensive AI capabilities, including: - Crafting advanced machine learning models. - Elevating communication with natural language processing. - Mastering intricate data analysis through deep learning applications. - Optimizing processes with streamlined, data-driven automation.\n\n\n\nHarness the power of industry-standard tools and technologies within our AI solutions: - TensorFlow and PyTorch for robust machine learning. - NLP prowess with NLTK and spaCy. - Cutting-edge frameworks for deep learning. - Seamless integration through automation platforms.\n\n\n\nWitness the tangible impact of our recent AI endeavors: - Precision in predictive analytics with sophisticated machine learning models. - Elevated communication and understanding through NLP solutions. - Advanced image and pattern recognition with deep learning applications.\n\n\n\nWhether you have specific AI requirements or aspire to innovate, let’s connect and explore how our end-to-end AI expertise can elevate and transform your business operations."
  },
  {
    "objectID": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html#tailored-ai-excellence",
    "href": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html#tailored-ai-excellence",
    "title": "Artificial Intelligence",
    "section": "",
    "text": "Experience the pinnacle of AI solutions tailored precisely to your unique business demands, leveraging a suite of sophisticated tools and technologies."
  },
  {
    "objectID": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html#end-to-end-ai-mastery",
    "href": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html#end-to-end-ai-mastery",
    "title": "Artificial Intelligence",
    "section": "",
    "text": "Embark on a journey of comprehensive AI capabilities, including: - Crafting advanced machine learning models. - Elevating communication with natural language processing. - Mastering intricate data analysis through deep learning applications. - Optimizing processes with streamlined, data-driven automation."
  },
  {
    "objectID": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html#tools-and-technologies",
    "href": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html#tools-and-technologies",
    "title": "Artificial Intelligence",
    "section": "",
    "text": "Harness the power of industry-standard tools and technologies within our AI solutions: - TensorFlow and PyTorch for robust machine learning. - NLP prowess with NLTK and spaCy. - Cutting-edge frameworks for deep learning. - Seamless integration through automation platforms."
  },
  {
    "objectID": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html#recent-ai-triumphs",
    "href": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html#recent-ai-triumphs",
    "title": "Artificial Intelligence",
    "section": "",
    "text": "Witness the tangible impact of our recent AI endeavors: - Precision in predictive analytics with sophisticated machine learning models. - Elevated communication and understanding through NLP solutions. - Advanced image and pattern recognition with deep learning applications."
  },
  {
    "objectID": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html#propel-your-operations-forward",
    "href": "core/solutions/1_Artificial Intelligence/artificial_intelligence.html#propel-your-operations-forward",
    "title": "Artificial Intelligence",
    "section": "",
    "text": "Whether you have specific AI requirements or aspire to innovate, let’s connect and explore how our end-to-end AI expertise can elevate and transform your business operations."
  },
  {
    "objectID": "core/solutions/4_Web Application/webapplication.html",
    "href": "core/solutions/4_Web Application/webapplication.html",
    "title": "Web Application",
    "section": "",
    "text": "Step into the future of online interaction with our Web Application services. We create user-friendly websites to make your business stand out.\n\n\nGet a website that suits your business perfectly. We use modern technology to build websites that work just right for you.\n\n\n\nWe cover everything your website needs: - Easy-to-use design. - Features that make your website work well. - Designs that look good on phones, tablets, and computers. - Behind-the-scenes technology to manage your data smoothly.\n\n\n\nWe use top-notch tools to make your website awesome: - Modern design tools like React, Angular, or Vue.js. - Strong backend tools like Node.js, Django, or Flask. - Different types of databases to store information. - Cloud services to make sure your website can handle lots of visitors.\n\n\n\nSee how our recent websites have made a difference: - Easy-to-use interfaces that people love. - Features that make websites work better. - Connecting everything behind the scenes to keep information organized.\n\n\n\nWhether you have a specific website idea or want to improve your online presence, let’s talk. We can make your online experience better!"
  },
  {
    "objectID": "core/solutions/4_Web Application/webapplication.html#personalized-web-solutions",
    "href": "core/solutions/4_Web Application/webapplication.html#personalized-web-solutions",
    "title": "Web Application",
    "section": "",
    "text": "Get a website that suits your business perfectly. We use modern technology to build websites that work just right for you."
  },
  {
    "objectID": "core/solutions/4_Web Application/webapplication.html#all-inclusive-website-development",
    "href": "core/solutions/4_Web Application/webapplication.html#all-inclusive-website-development",
    "title": "Web Application",
    "section": "",
    "text": "We cover everything your website needs: - Easy-to-use design. - Features that make your website work well. - Designs that look good on phones, tablets, and computers. - Behind-the-scenes technology to manage your data smoothly."
  },
  {
    "objectID": "core/solutions/4_Web Application/webapplication.html#our-tools",
    "href": "core/solutions/4_Web Application/webapplication.html#our-tools",
    "title": "Web Application",
    "section": "",
    "text": "We use top-notch tools to make your website awesome: - Modern design tools like React, Angular, or Vue.js. - Strong backend tools like Node.js, Django, or Flask. - Different types of databases to store information. - Cloud services to make sure your website can handle lots of visitors."
  },
  {
    "objectID": "core/solutions/4_Web Application/webapplication.html#recent-website-successes",
    "href": "core/solutions/4_Web Application/webapplication.html#recent-website-successes",
    "title": "Web Application",
    "section": "",
    "text": "See how our recent websites have made a difference: - Easy-to-use interfaces that people love. - Features that make websites work better. - Connecting everything behind the scenes to keep information organized."
  },
  {
    "objectID": "core/solutions/4_Web Application/webapplication.html#boost-your-online-presence",
    "href": "core/solutions/4_Web Application/webapplication.html#boost-your-online-presence",
    "title": "Web Application",
    "section": "",
    "text": "Whether you have a specific website idea or want to improve your online presence, let’s talk. We can make your online experience better!"
  },
  {
    "objectID": "core/solutions/3_Webscraping/webscraping.html",
    "href": "core/solutions/3_Webscraping/webscraping.html",
    "title": "Web Scraping",
    "section": "",
    "text": "Explore our comprehensive suite of services, offering web scraping, data mining, and data extraction solutions tailored for lead generation, business process automation, research, and marketing initiatives.\n\n\nOur web scrapers, written in Python (utilizing BeautifulSoup, Requests, Selenium), ensure precise data extraction, filtration, and packaging in versatile formats, including CSV, JSON, and XML.\n\n\n\n\nExtract data tables, text, images, and links, among other elements.\nFilter and compile data into various formats: JSON, XML, CSV, and SQL.\nSet up alerts for new content discovery.\nCapture screenshots or download full HTML of websites.\nConduct “real” interactions with websites, including clicking buttons, accessing drop-downs, and entering text into forms.\n\n\n\n\nUtilizing Python BeautifulSoup, Requests, Selenium, and Headless Chrome.\n\n\n\n\nSystem to rename thousands of images files stored in Dropbox using Python and Dropbox API.\nWeb app to translate Excel documents with Python Flask and Google Cloud Translation API.\nScraped a list of 100,000 funeral homes across the U.S.\nScraped a list of 3,000 martial arts institutes in the UK, identifying site tools, mobile responsiveness, and page load speed.\nAutomated scraping of property listings and publishing to a WordPress site.\nScraped product listings from a home appliances vendor using Selenium.\nDeveloped a system to scrape job listings from Indeed and import into a WordPress-based website.\n\n\n\n\nDo you have a web scraping, data extraction, or business process automation requirement? Let’s discuss how we can elevate your operations."
  },
  {
    "objectID": "core/solutions/3_Webscraping/webscraping.html#custom-web-scrapers",
    "href": "core/solutions/3_Webscraping/webscraping.html#custom-web-scrapers",
    "title": "Web Scraping",
    "section": "",
    "text": "Our web scrapers, written in Python (utilizing BeautifulSoup, Requests, Selenium), ensure precise data extraction, filtration, and packaging in versatile formats, including CSV, JSON, and XML."
  },
  {
    "objectID": "core/solutions/3_Webscraping/webscraping.html#web-scraping-features",
    "href": "core/solutions/3_Webscraping/webscraping.html#web-scraping-features",
    "title": "Web Scraping",
    "section": "",
    "text": "Extract data tables, text, images, and links, among other elements.\nFilter and compile data into various formats: JSON, XML, CSV, and SQL.\nSet up alerts for new content discovery.\nCapture screenshots or download full HTML of websites.\nConduct “real” interactions with websites, including clicking buttons, accessing drop-downs, and entering text into forms."
  },
  {
    "objectID": "core/solutions/3_Webscraping/webscraping.html#scraping-tools",
    "href": "core/solutions/3_Webscraping/webscraping.html#scraping-tools",
    "title": "Web Scraping",
    "section": "",
    "text": "Utilizing Python BeautifulSoup, Requests, Selenium, and Headless Chrome."
  },
  {
    "objectID": "core/solutions/3_Webscraping/webscraping.html#recent-projects",
    "href": "core/solutions/3_Webscraping/webscraping.html#recent-projects",
    "title": "Web Scraping",
    "section": "",
    "text": "System to rename thousands of images files stored in Dropbox using Python and Dropbox API.\nWeb app to translate Excel documents with Python Flask and Google Cloud Translation API.\nScraped a list of 100,000 funeral homes across the U.S.\nScraped a list of 3,000 martial arts institutes in the UK, identifying site tools, mobile responsiveness, and page load speed.\nAutomated scraping of property listings and publishing to a WordPress site.\nScraped product listings from a home appliances vendor using Selenium.\nDeveloped a system to scrape job listings from Indeed and import into a WordPress-based website."
  },
  {
    "objectID": "core/solutions/3_Webscraping/webscraping.html#get-in-touch",
    "href": "core/solutions/3_Webscraping/webscraping.html#get-in-touch",
    "title": "Web Scraping",
    "section": "",
    "text": "Do you have a web scraping, data extraction, or business process automation requirement? Let’s discuss how we can elevate your operations."
  },
  {
    "objectID": "core/about.html",
    "href": "core/about.html",
    "title": "Aakash Basnet",
    "section": "",
    "text": "Greetings! I’m Aakash Basnet, a Software Engineer with 6 years of hands-on experience.\nMy journey involves working closely with clients as a consultant, where I’ve tackled various projects, from crafting web applications and dashboards to implementing machine learning solutions and web scraping tools. I take pride in simplifying complex tech challenges and creating solutions that align with clients’ unique needs.\nBeyond coding, I find joy in hiking, mountain biking, boxing and reading, maintaining a healthy work-life balance. Let’s connect and explore how we can create something exceptional together!\nSchedule time with Aakash\nDownload CV"
  },
  {
    "objectID": "core/about.html#education",
    "href": "core/about.html#education",
    "title": "Aakash Basnet",
    "section": "Education",
    "text": "Education\nUniversity of New Mexico, Bsc. in Computer Science| Dec 2018.\nCumberland University, Msc. in Information Technology | May 2023."
  },
  {
    "objectID": "core/about.html#skills",
    "href": "core/about.html#skills",
    "title": "Aakash Basnet",
    "section": "Skills",
    "text": "Skills\nProgramming language: Python, Javascript, HTML, CSS, Matlab, C, Haskell\nFrameworks: Flask, FastAPI,Django, Scrapy, beautifulsoup, selenium,Quarto, Airflow, Pyspark\nCI/CD : git, Docker\nDatabase: SQL, NoSQL, HDFS\nCloud: AWS( EC2, S3, RDS, Lamba, SQS, Sagemaker)\nTools: Nginx, gUnicorn, guvicorn, cornjob\nData analysis and Machine learning: Keras, Tensorfolw, pyTorch, scikit-learn, pandas, numpy, matplotlib"
  },
  {
    "objectID": "core/about.html#experience",
    "href": "core/about.html#experience",
    "title": "Aakash Basnet",
    "section": "Experience",
    "text": "Experience\nBank of America | Backend Big Data/ Machine learning Engineer | June 2022 - Jan 2024\nPennyMac | Backend/Machine Learning Engineer | August 2021 - May 2022\nVitol | Backend/ Machine Learning Engineer | April 2020 - July 2021\nBank of America | Full Stack Engineer | April 2019 - Dec 2019\nBBER | Full Stack Developer (internship) | May 2018 - Dec 2018\nCAPS| Programming/Math Tutor | Jan 2016 - June 2018"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Freelancer , with 6 years of experiences",
    "section": "",
    "text": "Freelancer , with 6 years of experiences\n\nI specialize in Python automation, data engineering, and developing impactful web applications and dashboards. Let’s collaborate to enhance your operational efficiency and unlock the potential of data-driven insights.\n\n\n\nContact Me\n\n\nLearn More\n\n\n\nServices\nEmbark on a transformative journey with my freelance services in IT and Finance Solutions. With over 6 years of experience, I specialize in Python automation, data engineering, and crafting impactful web applications and dashboards. As a seasoned freelancer, I bring a holistic approach to addressing complex challenges. My proficiency extends to designing robust ETL pipelines and implementing machine learning and AI tools to keep you at the forefront of technological innovation. Explore my portfolio for successful projects, and let’s collaborate to enhance your operational efficiency and unlock the potential of data-driven insights. Contact me today to discuss how we can tailor these advanced solutions to meet your unique business needs  \n\n\n\n\n\n\n\n\n\n\n\nArtificial Intelligence\n\n\n“I provide artificial intelligence service to business and client”\n\n\nEnhance your data capabilities with our specialized web scraping services, tailored for efficient data extraction, smooth automation, and real-time content discovery to elevate your decision-making processes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nConsulting\n\n\n“I provide consulting service to business and client”\n\n\nEnhance your data capabilities with our specialized web scraping services, tailored for efficient data extraction, smooth automation, and real-time content discovery to elevate your decision-making processes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Engineering\n\n\n“I provide data engineering solution to business and clients.”\n\n\nBoost your data capabilities with our streamlined data engineering services, featuring efficient ETL pipeline development, Apache Airflow orchestration, and scalable AWS solutions for actionable insights.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTutoring\n\n\n“I provide tutoring / mentoring service to business and client”\n\n\nEnhance your data capabilities with our specialized web scraping services, tailored for efficient data extraction, smooth automation, and real-time content discovery to elevate your decision-making processes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb Application\n\n\n“I provide Web application service to business and client”\n\n\nEnhance your data capabilities with our specialized web scraping services, tailored for efficient data extraction, smooth automation, and real-time content discovery to elevate your decision-making processes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb Scraping\n\n\n“I provide Web scraping service to business and client”\n\n\nEnhance your data capabilities with our specialized web scraping services, tailored for efficient data extraction, smooth automation, and real-time content discovery to elevate your decision-making processes.\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\nTestimonials\nThese are the testimonials from the awesome peoples that i have worked in the past.\n \n\n\n\n\n\n\n\n\n\n\n\nHimanshu Chaudhary\n\n\nFull Stack Engineer at Wealthfront\n\n\n“Enhance your data capabilities with our specialized web scraping services, tailored for efficient data extraction, smooth automation, and real-time content discovery to elevate your decision-making processes.”\n\n\n\n\n\n\n\n\n\n\n\n\n\nSarun Luitel\n\n\nData Engineer at UNM BBER\n\n\n“Boost your data capabilities with our streamlined data engineering services, featuring efficient ETL pipeline development, Apache Airflow orchestration, and scalable AWS solutions for actionable insights.”\n\n\n\n\n\n\n\n\n\n\n\n\n\nTyler Ryan\n\n\nCMO at Randstad Technologies\n\n\n“Enhance your data capabilities with our specialized web scraping services, tailored for efficient data extraction, smooth automation, and real-time content discovery to elevate your decision-making processes.”\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "core/404.html",
    "href": "core/404.html",
    "title": "Page Not Found",
    "section": "",
    "text": "The page you requested cannot be found (perhaps it was moved or renamed).\nYou may want to try searching to find the page’s new location.\n\n\n\n Back to top"
  },
  {
    "objectID": "core/solutions/2_Data Engineering/data-engineering.html",
    "href": "core/solutions/2_Data Engineering/data-engineering.html",
    "title": "Data Engineering",
    "section": "",
    "text": "Discover our versatile data engineering services designed to optimize your data infrastructure and drive actionable insights across your organization.\n\n\nWe specialize in crafting tailored data engineering solutions to meet your specific business needs, leveraging a variety of tools and technologies.\n\n\n\n\nEfficient ETL (Extract, Transform, Load) pipeline development.\nStreamlining data workflows for improved efficiency.\nData cleansing, transformation, and enrichment processes.\nIntegration of diverse data sources for comprehensive analysis.\nImplementing scalable and robust data architectures.\n\n\n\n\nOur data engineering solutions make use of industry-standard tools and technologies, ensuring reliability and performance in handling your data:\n\nApache Airflow for orchestration and scheduling.\nApache Spark for distributed data processing.\nApache Hadoop for large-scale data storage and processing.\nSQL-based databases (e.g., PostgreSQL, MySQL).\nNoSQL databases (e.g., MongoDB, Cassandra).\nCloud-based data services, particularly AWS for scalable and secure solutions.\n\n\n\n\nExplore some of our recent successes in the realm of data engineering:\n\nDevelopment of a scalable ETL pipeline using Apache Airflow for real-time data processing.\nImplementation of data cleansing and enrichment processes for improved data quality.\nIntegration of various data sources into AWS for unified business intelligence.\n\n\n\n\nIf you have data engineering requirements or are looking to optimize your data processes, let’s connect and explore how our expertise can elevate your data infrastructure."
  },
  {
    "objectID": "core/solutions/2_Data Engineering/data-engineering.html#custom-data-engineering-solutions",
    "href": "core/solutions/2_Data Engineering/data-engineering.html#custom-data-engineering-solutions",
    "title": "Data Engineering",
    "section": "",
    "text": "We specialize in crafting tailored data engineering solutions to meet your specific business needs, leveraging a variety of tools and technologies."
  },
  {
    "objectID": "core/solutions/2_Data Engineering/data-engineering.html#data-engineering-capabilities",
    "href": "core/solutions/2_Data Engineering/data-engineering.html#data-engineering-capabilities",
    "title": "Data Engineering",
    "section": "",
    "text": "Efficient ETL (Extract, Transform, Load) pipeline development.\nStreamlining data workflows for improved efficiency.\nData cleansing, transformation, and enrichment processes.\nIntegration of diverse data sources for comprehensive analysis.\nImplementing scalable and robust data architectures."
  },
  {
    "objectID": "core/solutions/2_Data Engineering/data-engineering.html#tools-and-technologies",
    "href": "core/solutions/2_Data Engineering/data-engineering.html#tools-and-technologies",
    "title": "Data Engineering",
    "section": "",
    "text": "Our data engineering solutions make use of industry-standard tools and technologies, ensuring reliability and performance in handling your data:\n\nApache Airflow for orchestration and scheduling.\nApache Spark for distributed data processing.\nApache Hadoop for large-scale data storage and processing.\nSQL-based databases (e.g., PostgreSQL, MySQL).\nNoSQL databases (e.g., MongoDB, Cassandra).\nCloud-based data services, particularly AWS for scalable and secure solutions."
  },
  {
    "objectID": "core/solutions/2_Data Engineering/data-engineering.html#recent-data-engineering-projects",
    "href": "core/solutions/2_Data Engineering/data-engineering.html#recent-data-engineering-projects",
    "title": "Data Engineering",
    "section": "",
    "text": "Explore some of our recent successes in the realm of data engineering:\n\nDevelopment of a scalable ETL pipeline using Apache Airflow for real-time data processing.\nImplementation of data cleansing and enrichment processes for improved data quality.\nIntegration of various data sources into AWS for unified business intelligence."
  },
  {
    "objectID": "core/solutions/2_Data Engineering/data-engineering.html#lets-enhance-your-data-infrastructure",
    "href": "core/solutions/2_Data Engineering/data-engineering.html#lets-enhance-your-data-infrastructure",
    "title": "Data Engineering",
    "section": "",
    "text": "If you have data engineering requirements or are looking to optimize your data processes, let’s connect and explore how our expertise can elevate your data infrastructure."
  },
  {
    "objectID": "core/solutions/6_Consulting/consulting.html",
    "href": "core/solutions/6_Consulting/consulting.html",
    "title": "Consulting",
    "section": "",
    "text": "Enhance your business with tailored consulting services covering software engineering, data engineering, data pipeline design, AI solutions, web scraping, and lead generation. Our expertise is here to guide you towards effective solutions.\n\n\nReceive personalized advice and strategies to optimize your software development processes, ensuring efficient and robust solutions.\n\n\n\nUnlock the potential of your data infrastructure with consulting in data engineering, including ETL pipelines, database design, and data architecture.\n\n\n\nGet insights into designing effective data pipelines that streamline the flow of information, ensuring seamless data processing.\n\n\n\nExplore the possibilities of AI for your business with expert consultation, covering machine learning models, natural language processing, and AI integration.\n\n\n\nGain an edge in data extraction and automation with consulting on web scraping techniques, tools, and best practices.\n\n\n\nTransform your business with lead generation strategies, leveraging data-driven approaches for targeted and effective outreach.\n\n\n\nWe provide: - Personalized consultations tailored to your business needs. - Practical strategies to implement efficient solutions. - Expert guidance in navigating complex technological challenges.\n\n\n\nDiscover how our consulting services have made a difference: - Optimizing software development processes. - Enhancing data infrastructure for improved insights. - Designing effective data pipelines for streamlined operations. - Implementing successful AI solutions for various industries. - Crafting web scraping strategies for data-driven decision-making. - Boosting lead generation efforts with targeted approaches.\n\n\n\nWhether you’re seeking advice on software engineering, data solutions, or strategic insights for AI, web scraping, and lead generation, let’s connect. Our consulting services are here to guide you toward effective and impactful solutions."
  },
  {
    "objectID": "core/solutions/6_Consulting/consulting.html#software-engineering-consultation",
    "href": "core/solutions/6_Consulting/consulting.html#software-engineering-consultation",
    "title": "Consulting",
    "section": "",
    "text": "Receive personalized advice and strategies to optimize your software development processes, ensuring efficient and robust solutions."
  },
  {
    "objectID": "core/solutions/6_Consulting/consulting.html#data-engineering-expertise",
    "href": "core/solutions/6_Consulting/consulting.html#data-engineering-expertise",
    "title": "Consulting",
    "section": "",
    "text": "Unlock the potential of your data infrastructure with consulting in data engineering, including ETL pipelines, database design, and data architecture."
  },
  {
    "objectID": "core/solutions/6_Consulting/consulting.html#data-pipeline-design",
    "href": "core/solutions/6_Consulting/consulting.html#data-pipeline-design",
    "title": "Consulting",
    "section": "",
    "text": "Get insights into designing effective data pipelines that streamline the flow of information, ensuring seamless data processing."
  },
  {
    "objectID": "core/solutions/6_Consulting/consulting.html#ai-solutions-consulting",
    "href": "core/solutions/6_Consulting/consulting.html#ai-solutions-consulting",
    "title": "Consulting",
    "section": "",
    "text": "Explore the possibilities of AI for your business with expert consultation, covering machine learning models, natural language processing, and AI integration."
  },
  {
    "objectID": "core/solutions/6_Consulting/consulting.html#web-scraping-strategies",
    "href": "core/solutions/6_Consulting/consulting.html#web-scraping-strategies",
    "title": "Consulting",
    "section": "",
    "text": "Gain an edge in data extraction and automation with consulting on web scraping techniques, tools, and best practices."
  },
  {
    "objectID": "core/solutions/6_Consulting/consulting.html#lead-generation-insights",
    "href": "core/solutions/6_Consulting/consulting.html#lead-generation-insights",
    "title": "Consulting",
    "section": "",
    "text": "Transform your business with lead generation strategies, leveraging data-driven approaches for targeted and effective outreach."
  },
  {
    "objectID": "core/solutions/6_Consulting/consulting.html#our-approach",
    "href": "core/solutions/6_Consulting/consulting.html#our-approach",
    "title": "Consulting",
    "section": "",
    "text": "We provide: - Personalized consultations tailored to your business needs. - Practical strategies to implement efficient solutions. - Expert guidance in navigating complex technological challenges."
  },
  {
    "objectID": "core/solutions/6_Consulting/consulting.html#recent-success-stories",
    "href": "core/solutions/6_Consulting/consulting.html#recent-success-stories",
    "title": "Consulting",
    "section": "",
    "text": "Discover how our consulting services have made a difference: - Optimizing software development processes. - Enhancing data infrastructure for improved insights. - Designing effective data pipelines for streamlined operations. - Implementing successful AI solutions for various industries. - Crafting web scraping strategies for data-driven decision-making. - Boosting lead generation efforts with targeted approaches."
  },
  {
    "objectID": "core/solutions/6_Consulting/consulting.html#elevate-your-business-strategies",
    "href": "core/solutions/6_Consulting/consulting.html#elevate-your-business-strategies",
    "title": "Consulting",
    "section": "",
    "text": "Whether you’re seeking advice on software engineering, data solutions, or strategic insights for AI, web scraping, and lead generation, let’s connect. Our consulting services are here to guide you toward effective and impactful solutions."
  },
  {
    "objectID": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html",
    "href": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html",
    "title": "Tutoring",
    "section": "",
    "text": "Enhance your proficiency in Python, programming, software engineering, and AI through our tutoring and mentoring service. We offer tailored guidance to individuals and foster collaborative learning in group sessions, ensuring a well-rounded educational experience.\n\n\nGet a tutoring experience that’s just right for you. We provide one-on-one sessions for personalized attention, focusing on Python, programming, software engineering, and AI to meet your specific learning goals.\n\n\n\nJoin our group sessions for a collaborative learning environment. Engage with peers as we explore a range of topics together, covering Python basics, programming languages like Java or JavaScript, software engineering principles, and the fundamentals of Artificial Intelligence.\n\n\n\nExplore a variety of topics, including: - Python basics and advanced concepts. - Programming languages such as Java, C++, or JavaScript. - Software engineering principles and best practices. - Introduction to Artificial Intelligence and machine learning.\n\n\n\nWe use a friendly and approachable style to teach: - Step-by-step learning for ease of understanding. - Practical examples to apply what you learn. - Guidance in building real-world projects.\n\n\n\nDiscover how our tutor"
  },
  {
    "objectID": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html#personalized-learning-experience",
    "href": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html#personalized-learning-experience",
    "title": "Tutoring",
    "section": "",
    "text": "Get a tutoring experience that’s just right for you. We provide one-on-one sessions for personalized attention, focusing on Python, programming, software engineering, and AI to meet your specific learning goals."
  },
  {
    "objectID": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html#group-learning-atmosphere",
    "href": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html#group-learning-atmosphere",
    "title": "Tutoring",
    "section": "",
    "text": "Join our group sessions for a collaborative learning environment. Engage with peers as we explore a range of topics together, covering Python basics, programming languages like Java or JavaScript, software engineering principles, and the fundamentals of Artificial Intelligence."
  },
  {
    "objectID": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html#what-we-cover",
    "href": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html#what-we-cover",
    "title": "Tutoring",
    "section": "",
    "text": "Explore a variety of topics, including: - Python basics and advanced concepts. - Programming languages such as Java, C++, or JavaScript. - Software engineering principles and best practices. - Introduction to Artificial Intelligence and machine learning."
  },
  {
    "objectID": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html#our-approach",
    "href": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html#our-approach",
    "title": "Tutoring",
    "section": "",
    "text": "We use a friendly and approachable style to teach: - Step-by-step learning for ease of understanding. - Practical examples to apply what you learn. - Guidance in building real-world projects."
  },
  {
    "objectID": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html#recent-success-stories",
    "href": "core/solutions/5_Tutoring and Mentoring/tutoring_and_mentoring.html#recent-success-stories",
    "title": "Tutoring",
    "section": "",
    "text": "Discover how our tutor"
  },
  {
    "objectID": "core/contact.html",
    "href": "core/contact.html",
    "title": "Contact",
    "section": "",
    "text": "Thank you for your interest in reaching out to me.\nWhether you have queries, require consulting services, or are seeking solutions, I’m here to help. Your questions matter, and I’d love to receive your message.I am committed to providing prompt and personalized responses to address your specific needs.\nYou can use the contact form below to get in touch, or if you prefer, schedule a meeting  at your convenience.\n\n \n\nEmail *\n  \n\n\nSubject *\n  \n\n\nMessage *\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "core/blogs/indeed/indeed-job-scraper.html",
    "href": "core/blogs/indeed/indeed-job-scraper.html",
    "title": "Webscraping Indeed Job Portal",
    "section": "",
    "text": "After navigating the developer toolbar for Indeed job listing, I found the pattern in the url query for each job title search and location. We can use this info to build the url. The link printed from the code below will take you to the Indeed page having listing for python developer in Dalla, TX\n\n\nCode\ndef url_builder(job_title, location, page_number=10 ):\n    job_title = \"+\".join(job_title.split(\" \"))\n    location = \"+\".join(location.split(\" \"))\n    base_url = \"https://www.indeed.com/jobs\"\n    query_str = f\"?q={job_title}&l={location}\"\n    url = f\"{base_url}{query_str}\"\n     \n    return url\n\nprint(url_builder(job_title=\"python developer\", location=\"Dallas, TX\"))\n\n\nhttps://www.indeed.com/jobs?q=python+developer&l=Dallas,+TX"
  },
  {
    "objectID": "core/blogs/indeed/indeed-job-scraper.html#building-url",
    "href": "core/blogs/indeed/indeed-job-scraper.html#building-url",
    "title": "Webscraping Indeed Job Portal",
    "section": "",
    "text": "After navigating the developer toolbar for Indeed job listing, I found the pattern in the url query for each job title search and location. We can use this info to build the url. The link printed from the code below will take you to the Indeed page having listing for python developer in Dalla, TX\n\n\nCode\ndef url_builder(job_title, location, page_number=10 ):\n    job_title = \"+\".join(job_title.split(\" \"))\n    location = \"+\".join(location.split(\" \"))\n    base_url = \"https://www.indeed.com/jobs\"\n    query_str = f\"?q={job_title}&l={location}\"\n    url = f\"{base_url}{query_str}\"\n     \n    return url\n\nprint(url_builder(job_title=\"python developer\", location=\"Dallas, TX\"))\n\n\nhttps://www.indeed.com/jobs?q=python+developer&l=Dallas,+TX"
  },
  {
    "objectID": "core/blogs/indeed/indeed-job-scraper.html#scraping-the-indeep-page-with-selenium",
    "href": "core/blogs/indeed/indeed-job-scraper.html#scraping-the-indeep-page-with-selenium",
    "title": "Webscraping Indeed Job Portal",
    "section": "Scraping the indeep page with selenium",
    "text": "Scraping the indeep page with selenium\nThe script below scrapes the data for the given job title and location. It uses selenium web driver to automate the data scraping. The web driver clicks ‘next’ button on pagination until the end of the page.\n\n\nCode\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\nimport time\n\ndef get_data(job_title, location):\n\n    url = url_builder(job_title=job_title, location=location)\n    driver = webdriver.Chrome()\n    driver.get(url)\n\n    jobs = []\n    has_next = True\n    count = 1\n    while has_next:\n        \n        time.sleep(2)\n        cards = driver.find_elements(By.CLASS_NAME,'cardOutline')\n        for card in cards:\n            job_title = card.find_element(By.CLASS_NAME,'jobTitle')\n            job_title_text = job_title.text\n            job_id = job_title.find_element(By.TAG_NAME, 'a').get_attribute('data-jk')\n            location = card.find_element(By.CLASS_NAME,'company_location').text\n            job_description = card.find_element(By.CLASS_NAME,'underShelfFooter').text\n            \n            try:\n                pay,*_metadata = card.find_element(By.CLASS_NAME,'heading6').text.split('\\n')\n            except Exception as e:\n                pay = 'NA'\n                _metadata = []\n        \n            \n            jobs.append({\n                'job_title':job_title_text,\n                'location': location,\n                'description': job_description,\n                'pay rate': pay,\n                'metadata': _metadata,\n                'job_id':job_id,\n                'job_url': f\"https://www.indeed.com/viewjob?jk={job_id}\",\n                \n            })\n\n        try:\n            driver.find_element(By.CSS_SELECTOR,\"[data-testid='pagination-page-next']\").click()\n            count += 1\n        except Exception as e:\n            print(f\"Ending at page {count}\")\n            has_next = False\n\n    driver.close()\n    return jobs\n\n\n\n\n\nCode\njob_data = get_data(job_title='python developer', location='Fort Worth,TX')\n\n\n\nEnding at page 40\n\n\n\n\nCode\nimport pandas as pd\ndf = pd.DataFrame(job_data)\ndf.head(40)\n\n\n\n\n\n\n\n\n\n\njob_title\nlocation\ndescription\npay rate\nmetadata\njob_id\njob_url\n\n\n\n\n0\nSoftware Developer - AI Trainer (Contract)\nDataAnnotation\\n4.6\\nRemote in Dallas, TX\nYou will work with the chatbots that we are bu...\n$40 an hour\n[Contract, 1 to 40 hours per week, Choose your...\ncd937da8c0f30efd\nhttps://www.indeed.com/viewjob?jk=cd937da8c0f3...\n\n\n1\nPython Developer\nRobert Half\\n3.9\\nPlano, TX 75024\nPeriodically exercise code-review and band tog...\n$76 - $88 an hour\n[Temp-to-hire]\naeb409d79f39f2e1\nhttps://www.indeed.com/viewjob?jk=aeb409d79f39...\n\n\n2\nBack End Developer\nIWP Services, LLC\\nHybrid remote in Fort Worth...\nIntegration of user-facing elements developed ...\n$100,000 - $110,000 a year\n[Full-time, +1, Monday to Friday, Employee sto...\ndc3e79c2af261bbe\nhttps://www.indeed.com/viewjob?jk=dc3e79c2af26...\n\n\n3\nDevOps Engineer (309801)\nInternal Data Resources\\n3.7\\nRemote in Coppel...\nOur client is looking for a DevOps Engineer to...\n$55 - $63 an hour\n[Full-time, 40 hours per week, 8 hour shift]\n1ebb8e02e8eb7b07\nhttps://www.indeed.com/viewjob?jk=1ebb8e02e8eb...\n\n\n4\nPython Developer\nEmonics LLC\\nFort Worth, TX 76107 \\n(Arlington...\n8.Coordinating with front-end developers..\\nTo...\n$70,000 - $130,000 a year\n[Full-time, +1]\n8d0dfc501ff3fb89\nhttps://www.indeed.com/viewjob?jk=8d0dfc501ff3...\n\n\n5\nSoftware Engineer III (API / Scripting / Python)\nJPMorgan Chase & Co\\n3.9\\nPlano, TX 75024\nYour collaboration will be crucial in advancin...\nPay information not provided\n[Full-time]\nb7109d2b1ce04d16\nhttps://www.indeed.com/viewjob?jk=b7109d2b1ce0...\n\n\n6\nSoftware Developer\nBoston Enterprises Investment Group LLC\\nDeSot...\nThe ideal candidate will be passionate about d...\n$68,000 - $77,000 a year\n[Full-time, +1, 8 hour shift]\n8e5cb88d329ff384\nhttps://www.indeed.com/viewjob?jk=8e5cb88d329f...\n\n\n7\nPrincipal Artificial Intelligence / Machine Le...\nRaytheon\\n3.9\\nRichardson, TX 75082\nIn this role, you will work with data scientis...\n$96,000 - $200,000 a year\n[Full-time]\nab702435728c8649\nhttps://www.indeed.com/viewjob?jk=ab702435728c...\n\n\n8\nPython Developer\nQatalys Software Technologies\\nIrving, TX\nAnalyzes business and technical requirements t...\n\n[]\na2a8cbd917cbf446\nhttps://www.indeed.com/viewjob?jk=a2a8cbd917cb...\n\n\n9\nSoftware Engineer - Mid-Career (HYBRID TELEWORK)\nLockheed Martin Corporation\\nFort Worth, TX\nDesign, modify, develop, write, and implement ...\nPay information not provided\n[Full-time, 4x10]\n91cdaee932850a17\nhttps://www.indeed.com/viewjob?jk=91cdaee93285...\n\n\n10\nFull Stack Software Engineer (hybrid)\nRaytheon\\n3.9\\nRichardson, TX 75082\nExperience with the Linux shell scripting, pyt...\n$77,000 - $163,000 a year\n[Full-time]\n536f5c4b6cd40276\nhttps://www.indeed.com/viewjob?jk=536f5c4b6cd4...\n\n\n11\nLead Software Developer\nMcKesson\\nIrving, TX 75039 \\n(Freeport/Hackber...\nJava, Python, VB Scripts, Linux, SQL developer...\n$140,000 - $221,900 a year\n[]\nec178dacdbfc1516\nhttps://www.indeed.com/viewjob?jk=ec178dacdbfc...\n\n\n12\nJava AWS Full Stack Developer\nCGI Group, Inc.\\n3.6\\nTexas\nWe are seeking an AWS/JAVA Full Stack Develope...\nPay information not provided\n[Full-time]\n2e5a7704804e0172\nhttps://www.indeed.com/viewjob?jk=2e5a7704804e...\n\n\n13\nPython Developer\nNLB Technology Services\\nFort Worth, TX 76102\nMinimum 5 Years of relevant experience in Pyth...\n\n[]\nad783a919af67c7f\nhttps://www.indeed.com/viewjob?jk=ad783a919af6...\n\n\n14\nPython Developer (AWS)\nIntegrated Technology Strategies, Inc.\\nDallas...\nYou will participate and effectively contribut...\nPay information not provided\n[]\ncb1fe8a6b26f986f\nhttps://www.indeed.com/viewjob?jk=cb1fe8a6b26f...\n\n\n15\nExperienced Software Engineer Java / Python (F...\nJPMorgan Chase & Co\\n3.9\\nPlano, TX 75024\nDepending on the team that you join, you could...\nPay information not provided\n[Full-time]\nd2b8758d3e73f691\nhttps://www.indeed.com/viewjob?jk=d2b8758d3e73...\n\n\n16\nFront End Web Developer\nPCI Enterprises\\n4.3\\nDallas, TX\n2+ years experience with Javascript, HTML5 & C...\n$65,000 - $75,000 a year\n[Full-time, Monday to Friday, +1, Bonus opport...\n8f182ee73fc19368\nhttps://www.indeed.com/viewjob?jk=8f182ee73fc1...\n\n\n17\nApplication Developer- Java /Python\nHCL Tech\\nIrving, TX\nUS Citizen or GC Holder required due to ITAR R...\n$50.20 - $60.46 an hour\n[Full-time, Monday to Friday, +1]\na1434f80b52b2d66\nhttps://www.indeed.com/viewjob?jk=a1434f80b52b...\n\n\n18\nEngineering Aide - Programmer\nLockheed Martin Corporation\\nFort Worth, TX\nDescription:• Perform code analysis of existin...\nPay information not provided\n[Full-time, 4x10]\nb5c3dac533e8837f\nhttps://www.indeed.com/viewjob?jk=b5c3dac533e8...\n\n\n19\nWeb Developer\nTopgolf\\nDallas, TX 75231 \\n(Northeast Dallas ...\nDesign, develop, test, debug, and implement hi...\n\n[]\n7b274886df7b33e0\nhttps://www.indeed.com/viewjob?jk=7b274886df7b...\n\n\n20\nPython Developer\nKinetix Trading Solutions Inc\\nIrving, TX 75039\nOrganize with end users, business analysts, an...\n\n[]\n026deb02c0cf998d\nhttps://www.indeed.com/viewjob?jk=026deb02c0cf...\n\n\n21\nEmbedded Firmware Developer - IoT Apps\nWAC Lighting\\nCedar Hill, TX 75104\nDevelop well-tested, efficient, and maintainab...\nPay information not provided\n[]\naa2f1edfd956689a\nhttps://www.indeed.com/viewjob?jk=aa2f1edfd956...\n\n\n22\nMiddle/Senior Python Developer\nScienceSoft USA Corporation\\nRemote in Dallas, TX\nWrite high-quality, reusable and documented co...\n\n[]\n792d6bcda6668825\nhttps://www.indeed.com/viewjob?jk=792d6bcda666...\n\n\n23\nPython Developer\nThe Beneficient Company Group USA LLC\\nDallas,...\nStrong collaboration skills to work effectivel...\n\n[]\n4a341dd2109d5e28\nhttps://www.indeed.com/viewjob?jk=4a341dd2109d...\n\n\n24\nJunior Developer\nCALL BOX\\nDallas, TX 75231 \\n(Northeast Dallas...\nCreate and shape new products from the ground ...\n\n[]\n8ee9d97e2585c552\nhttps://www.indeed.com/viewjob?jk=8ee9d97e2585...\n\n\n25\nPython Developer\nMRoads\\nDallas, TX\nJOB TYPE: Contract(12+ months).\\nTeam is respo...\n\n[]\n018d5de40ecce815\nhttps://www.indeed.com/viewjob?jk=018d5de40ecc...\n\n\n26\nSr. PYTHON DEVELOPER\nAGILEWIT SOLUTIONS\\nLewisville, TX 75067\nExperience with project management and deliver...\nPay information not provided\n[]\n46c798ebcda00d7d\nhttps://www.indeed.com/viewjob?jk=46c798ebcda0...\n\n\n27\nFullStack Software Python/Node/React JS Developer\nElm Street Technology LLC\\nFrisco, TX 75033\nAs a FullStack Developer, you will develop and...\n\n[]\n1b46309123b68e9e\nhttps://www.indeed.com/viewjob?jk=1b46309123b6...\n\n\n28\nSoftware Developer\nMinol M T R Lp\\nAddison, TX 75001\nThe developer would leverage technical experti...\nPay information not provided\n[Full-time]\n3a0a3c9b2ac3af15\nhttps://www.indeed.com/viewjob?jk=3a0a3c9b2ac3...\n\n\n29\nSoftware Web Developer\nLockheed Martin Corporation\\nFort Worth, TX\nThe candidate should be a well-rounded softwar...\nPay information not provided\n[Full-time, 4x10]\nd282a472f4692ed2\nhttps://www.indeed.com/viewjob?jk=d282a472f469...\n\n\n30\nPython Developer\nRobert Half\\n3.9\\nPlano, TX 75024\nFrequently complete code-review and join force...\n$76 - $88 an hour\n[Temp-to-hire]\n9485e1c7aca04dda\nhttps://www.indeed.com/viewjob?jk=9485e1c7aca0...\n\n\n31\nDevOps Automation Engineer I\nGM Financial\\n3.6\\nHybrid remote in Arlington,...\nFinally, the engineer will be responsible for ...\n$76,400 - $141,300 a year\n[Full-time, On call, Bonus opportunities]\n73216f1f3f181f05\nhttps://www.indeed.com/viewjob?jk=73216f1f3f18...\n\n\n32\nPrincipal Artificial Intelligence / Machine Le...\nRaytheon\\n3.9\\nRichardson, TX 75082\nIn this role, you will work with data scientis...\n$96,000 - $200,000 a year\n[Full-time]\nab702435728c8649\nhttps://www.indeed.com/viewjob?jk=ab702435728c...\n\n\n33\nFull Stack Engineer\nPCI Enterprises\\n4.3\\nDallas, TX\n2+ years experience using any major backend pr...\n$65,000 - $80,000 a year\n[Full-time, Monday to Friday, +1, Bonus opport...\n693494f2bd167ac3\nhttps://www.indeed.com/viewjob?jk=693494f2bd16...\n\n\n34\nHadoop Developer\nMatlen Silver\\n3.3\\nPlano, TX\nMid Level Hadoop Developer (4-6 years of exper...\n$55 - $60 an hour\n[Contract, Hourly pay]\n48784392d6893ec6\nhttps://www.indeed.com/viewjob?jk=48784392d689...\n\n\n35\nQuantitative Risk, Model Developer- Market Ris...\nCiti\\n3.9\\nIrving, TX 75061\nDeveloped communication and diplomacy skills a...\n$125,760 - $188,640 a year\n[Full-time]\n0b51d40d49ef8a0a\nhttps://www.indeed.com/viewjob?jk=0b51d40d49ef...\n\n\n36\nSoftware Developer\nSeerist, Inc\\nHybrid remote in Dallas, TX\nCoding knowledge and experience with several l...\nPay information not provided\n[Full-time]\n251f54f954e7dead\nhttps://www.indeed.com/viewjob?jk=251f54f954e7...\n\n\n37\nPython Engineer\nCybeCys\\nPlano, TX\nReqs Master’s degree* in Information Systems o...\nPay information not provided\n[]\nfeb351ab034b044c\nhttps://www.indeed.com/viewjob?jk=feb351ab034b...\n\n\n38\nCloud Engineer\nCVS Health\\nIrving, TX\nCloud Engineer of Data Engineering will own th...\n$72,100 - $175,100 a year\n[Full-time]\n350b76a3bad7fff1\nhttps://www.indeed.com/viewjob?jk=350b76a3bad7...\n\n\n39\nAzure .NET Lead Developer\nVichara\\nDallas, TX 75211 \\n(Oak Cliff area)\nWork with development teams to provide estimat...\n$150,000 - $180,000 a year\n[]\nf74e65eb35fc2a33\nhttps://www.indeed.com/viewjob?jk=f74e65eb35fc...\n\n\n\n\n\n\n\n\n\n\nCode\ndf.shape\n\n\n(518, 7)"
  },
  {
    "objectID": "core/blogs/indeed/indeed-job-scraper.html#rotating-proxies",
    "href": "core/blogs/indeed/indeed-job-scraper.html#rotating-proxies",
    "title": "Webscraping Indeed Job Portal",
    "section": "Rotating Proxies",
    "text": "Rotating Proxies\nThe proxies needs to be rotated to not be detected by anti scrapping tools used by the servers. For this we will scrape the list of free available ip address and test them using multithreading. This will filter the working proxies. Later on, we will use working proxies to make the request\n\n\nCode\nimport pandas as pd\nimport requests\n\n\ndef extract_proxies():\n    print(\"Extracting proxies...\")\n    proxy_url  = \"https://www.us-proxy.org/\"\n    r = requests.get(proxy_url)\n    dfs  = pd.read_html(r.text)\n    df = dfs[0]\n    print(df.shape)\n    return df\nproxies_df = extract_proxies()\nproxies_df.head(20)\n   \n\n\n/var/folders/22/2rvpv_m90c30mhtk77k1jd440000gn/T/ipykernel_39218/3797928275.py:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n/var/folders/22/2rvpv_m90c30mhtk77k1jd440000gn/T/ipykernel_39218/3797928275.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dfs  = pd.read_html(r.text)\n\n\nExtracting proxies...\n(200, 8)\n\n\n\n\n\n\n\n\n\n\nIP Address\nPort\nCode\nCountry\nAnonymity\nGoogle\nHttps\nLast Checked\n\n\n\n\n0\n104.225.220.233\n80\nUS\nUnited States\nelite proxy\nyes\nno\n3 secs ago\n\n\n1\n23.254.231.55\n80\nUS\nUnited States\nelite proxy\nyes\nno\n3 secs ago\n\n\n2\n50.217.226.42\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n3\n50.223.239.185\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n4\n50.174.145.15\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n5\n50.174.214.220\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n6\n50.217.226.46\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n7\n50.200.12.83\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n8\n50.168.72.118\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n9\n50.207.199.85\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n10\n50.174.214.219\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n11\n68.185.57.66\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n12\n50.221.74.130\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n13\n50.174.145.8\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n14\n50.173.140.151\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n15\n50.168.72.115\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n16\n50.170.90.27\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n17\n50.168.163.176\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n18\n50.223.246.226\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago\n\n\n19\n50.207.199.84\n80\nUS\nUnited States\nanonymous\nno\nno\n4 secs ago"
  },
  {
    "objectID": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html",
    "href": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html",
    "title": "Himanshu Chaudhary",
    "section": "",
    "text": "Explore our comprehensive suite of services, offering web scraping, data mining, and data extraction solutions tailored for lead generation, business process automation, research, and marketing initiatives.\n\n\nOur web scrapers, written in Python (utilizing BeautifulSoup, Requests, Selenium), ensure precise data extraction, filtration, and packaging in versatile formats, including CSV, JSON, and XML.\n\n\n\n\nExtract data tables, text, images, and links, among other elements.\nFilter and compile data into various formats: JSON, XML, CSV, and SQL.\nSet up alerts for new content discovery.\nCapture screenshots or download full HTML of websites.\nConduct “real” interactions with websites, including clicking buttons, accessing drop-downs, and entering text into forms.\n\n\n\n\nUtilizing Python BeautifulSoup, Requests, Selenium, and Headless Chrome.\n\n\n\n\nSystem to rename thousands of images files stored in Dropbox using Python and Dropbox API.\nWeb app to translate Excel documents with Python Flask and Google Cloud Translation API.\nScraped a list of 100,000 funeral homes across the U.S.\nScraped a list of 3,000 martial arts institutes in the UK, identifying site tools, mobile responsiveness, and page load speed.\nAutomated scraping of property listings and publishing to a WordPress site.\nScraped product listings from a home appliances vendor using Selenium.\nDeveloped a system to scrape job listings from Indeed and import into a WordPress-based website.\n\n\n\n\nDo you have a web scraping, data extraction, or business process automation requirement? Let’s discuss how we can elevate your operations."
  },
  {
    "objectID": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html#custom-web-scrapers",
    "href": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html#custom-web-scrapers",
    "title": "Himanshu Chaudhary",
    "section": "",
    "text": "Our web scrapers, written in Python (utilizing BeautifulSoup, Requests, Selenium), ensure precise data extraction, filtration, and packaging in versatile formats, including CSV, JSON, and XML."
  },
  {
    "objectID": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html#web-scraping-features",
    "href": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html#web-scraping-features",
    "title": "Himanshu Chaudhary",
    "section": "",
    "text": "Extract data tables, text, images, and links, among other elements.\nFilter and compile data into various formats: JSON, XML, CSV, and SQL.\nSet up alerts for new content discovery.\nCapture screenshots or download full HTML of websites.\nConduct “real” interactions with websites, including clicking buttons, accessing drop-downs, and entering text into forms."
  },
  {
    "objectID": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html#scraping-tools",
    "href": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html#scraping-tools",
    "title": "Himanshu Chaudhary",
    "section": "",
    "text": "Utilizing Python BeautifulSoup, Requests, Selenium, and Headless Chrome."
  },
  {
    "objectID": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html#recent-projects",
    "href": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html#recent-projects",
    "title": "Himanshu Chaudhary",
    "section": "",
    "text": "System to rename thousands of images files stored in Dropbox using Python and Dropbox API.\nWeb app to translate Excel documents with Python Flask and Google Cloud Translation API.\nScraped a list of 100,000 funeral homes across the U.S.\nScraped a list of 3,000 martial arts institutes in the UK, identifying site tools, mobile responsiveness, and page load speed.\nAutomated scraping of property listings and publishing to a WordPress site.\nScraped product listings from a home appliances vendor using Selenium.\nDeveloped a system to scrape job listings from Indeed and import into a WordPress-based website."
  },
  {
    "objectID": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html#get-in-touch",
    "href": "core/testimonials/3_Himanshu_Chaudhary/Himanshu_Chaudhary.html#get-in-touch",
    "title": "Himanshu Chaudhary",
    "section": "",
    "text": "Do you have a web scraping, data extraction, or business process automation requirement? Let’s discuss how we can elevate your operations."
  },
  {
    "objectID": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html",
    "href": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html",
    "title": "Sarun Luitel",
    "section": "",
    "text": "Discover our versatile data engineering services designed to optimize your data infrastructure and drive actionable insights across your organization.\n\n\nWe specialize in crafting tailored data engineering solutions to meet your specific business needs, leveraging a variety of tools and technologies.\n\n\n\n\nEfficient ETL (Extract, Transform, Load) pipeline development.\nStreamlining data workflows for improved efficiency.\nData cleansing, transformation, and enrichment processes.\nIntegration of diverse data sources for comprehensive analysis.\nImplementing scalable and robust data architectures.\n\n\n\n\nOur data engineering solutions make use of industry-standard tools and technologies, ensuring reliability and performance in handling your data:\n\nApache Airflow for orchestration and scheduling.\nApache Spark for distributed data processing.\nApache Hadoop for large-scale data storage and processing.\nSQL-based databases (e.g., PostgreSQL, MySQL).\nNoSQL databases (e.g., MongoDB, Cassandra).\nCloud-based data services, particularly AWS for scalable and secure solutions.\n\n\n\n\nExplore some of our recent successes in the realm of data engineering:\n\nDevelopment of a scalable ETL pipeline using Apache Airflow for real-time data processing.\nImplementation of data cleansing and enrichment processes for improved data quality.\nIntegration of various data sources into AWS for unified business intelligence.\n\n\n\n\nIf you have data engineering requirements or are looking to optimize your data processes, let’s connect and explore how our expertise can elevate your data infrastructure."
  },
  {
    "objectID": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html#custom-data-engineering-solutions",
    "href": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html#custom-data-engineering-solutions",
    "title": "Sarun Luitel",
    "section": "",
    "text": "We specialize in crafting tailored data engineering solutions to meet your specific business needs, leveraging a variety of tools and technologies."
  },
  {
    "objectID": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html#data-engineering-capabilities",
    "href": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html#data-engineering-capabilities",
    "title": "Sarun Luitel",
    "section": "",
    "text": "Efficient ETL (Extract, Transform, Load) pipeline development.\nStreamlining data workflows for improved efficiency.\nData cleansing, transformation, and enrichment processes.\nIntegration of diverse data sources for comprehensive analysis.\nImplementing scalable and robust data architectures."
  },
  {
    "objectID": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html#tools-and-technologies",
    "href": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html#tools-and-technologies",
    "title": "Sarun Luitel",
    "section": "",
    "text": "Our data engineering solutions make use of industry-standard tools and technologies, ensuring reliability and performance in handling your data:\n\nApache Airflow for orchestration and scheduling.\nApache Spark for distributed data processing.\nApache Hadoop for large-scale data storage and processing.\nSQL-based databases (e.g., PostgreSQL, MySQL).\nNoSQL databases (e.g., MongoDB, Cassandra).\nCloud-based data services, particularly AWS for scalable and secure solutions."
  },
  {
    "objectID": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html#recent-data-engineering-projects",
    "href": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html#recent-data-engineering-projects",
    "title": "Sarun Luitel",
    "section": "",
    "text": "Explore some of our recent successes in the realm of data engineering:\n\nDevelopment of a scalable ETL pipeline using Apache Airflow for real-time data processing.\nImplementation of data cleansing and enrichment processes for improved data quality.\nIntegration of various data sources into AWS for unified business intelligence."
  },
  {
    "objectID": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html#lets-enhance-your-data-infrastructure",
    "href": "core/testimonials/2_Sarun_Luitel/sarun_luitel.html#lets-enhance-your-data-infrastructure",
    "title": "Sarun Luitel",
    "section": "",
    "text": "If you have data engineering requirements or are looking to optimize your data processes, let’s connect and explore how our expertise can elevate your data infrastructure."
  }
]